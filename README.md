## The course has two central parts

1. Statistical analysis and optimization of data
2. Machine learning

### Statistical analysis and optimization of data

The following topics will be covered
- Basic concepts, expectation values, variance, covariance, correlation functions and errors;
- Simpler models, binomial distribution, the Poisson distribution, simple and multivariate normal distributions;
- Central elements of Bayesian statistics and modeling;
- Central elements from linear algebra
- Cubic splines and gradient methods for data optimization
- Monte Carlo methods, Markov chains, Metropolis-Hastings algorithm, ergodicity;
- Linear methods for regression and classification;
- Estimation of errors using blocking, bootstrapping and jackknife methods;
- Practical optimization using Singular-value decomposition and least squares for parameterizing data.


### Machine learning

The following topics will be covered
- Gaussian and Dirichlet processes;
- Boltzmann machines;
- Neural networks;
- Decisions trees and nearest neighbor algorithms
- Support vector machines
- Genetic algorithms.

All the above topics will be supported by examples, hands-on exercises and project work.

Computational aspects play a central role and the students are
expected to work on numerical examples and projects which illustrate
the theory and methods. Some of the projects can be coordinated with the high-performance programming course (course code to be added). 



## Practicalities

1. Lectures are in the morning, from 9am-12pm.
2. Three hours of laboratory sessions for work on computational projects, from 2pm to 5pm;
3. Grading scale: Grades are awarded on a scale from A to F, where A is the best grade and F is a fail;


## Possible textbooks

_Recommended textbooks_:
- Trevor Hastie, Robert Tibshirani, Jerome H. Friedman, The Elements of Statistical Learning, Springer
- Aurelien Geron, Hands‑On Machine Learning with Scikit‑Learn and TensorFlow, O'Reilly

_General learning book on statistical analysis_:
- Christian Robert and George Casella, Monte Carlo Statistical Methods, Springer
- Peter Hoff, A first course in Bayesian statistical models, Springer

_General Machine Learning Books_:
- Kevin Murphy, Machine Learning: A Probabilistic Perspective, MIT Press
- Christopher M. Bishop, Pattern Recognition and Machine Learning, Springer
- David J.C. MacKay, Information Theory, Inference, and Learning Algorithms, Cambridge University Press
- David Barber, Bayesian Reasoning and Machine Learning, Cambridge University Press 




